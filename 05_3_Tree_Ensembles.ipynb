{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxQZCzxX5JYUwSSIWfQDjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jxxngho/HG_MLDL/blob/main/05_3_Tree_Ensembles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정형 데이터와 비정형 데이터"
      ],
      "metadata": {
        "id": "77MZkc8P36e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정형 데이터 : 데이터베이스에 저장할 수 있는 데이터( 행과 열이 구분된 데이터..), 레코드라고도 함. csv,엑셀에 저장\n",
        "# 비정형 데이터 : 책의 글과 같은 텍스트 데이터, 디지털 카메라로 찍은 사진, 디지털 음악 등등 ...\n",
        "\n",
        "# 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘은 앙상블 학습이다.\n",
        "# 이 알고리즘은 대부분 결정 트리를 기반으로 만들어져 있음.\n",
        "\n",
        "# 그럼 비정형 데이터에는 어떤 알고리즘을 사용해야하나?? -->> 신경망 알고리즘! (7장에서 배움)\n",
        "# 비정형 데이터는 규칙성을 찾기 어려워 전통적인 머신러닝 방법으로는 모델을 만들기 까다로움"
      ],
      "metadata": {
        "id": "-ZCqxZ-p38BY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트"
      ],
      "metadata": {
        "id": "bjxrTWk8NQZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트 : 결정 트리를 랜덤하게 만들어 결정 트리의 숲을 만든다\n",
        "# 이 후 결정 트리의 예측을 사용해 최종 예측을 만든다.\n",
        "\n",
        "# 랜덤 포레스트가 어떻게 숲을 구성???\n",
        "# 부트스트랩 샘플로 뽑는다 !! -> 중복을 허용한 샘플링\n",
        "# 부트스트랩 샘플로 결정 트리를 훈련하고 클래스별 확률을 다 더해서 트리 개수로 나눠준다.\n",
        "# 각 클래스별로 평균적 확률이 나옴! -> 제일 큰 것 결정\n",
        "\n",
        "# 랜덤 포레스트는 랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련 세트에 과대적합되는 것을 막아주고\n",
        "# 검증 세트와 테스트 세트에서 안정적인 성능을 얻을 수 있다."
      ],
      "metadata": {
        "id": "mRnnSMWBNRp8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "wine = pd.read_csv('http://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol','sugar','pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "SovCcPxIPgUe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_jobs=-1,random_state=42)\n",
        "\n",
        "# return_train_score = True로 지정하면 검증 점수 뿐만 아니라 훈련 세트에 대한 점수도 함께 반환한다.\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X685jn-5QJSH",
        "outputId": "5253c330-ab71-4189-81cb-99469a368ea3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 결과가 훈련 세트에 다소 과대적합 ..ㅜ"
      ],
      "metadata": {
        "id": "d_b8FIuwRBlT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 중요도 확인\n",
        "rf.fit(train_input,train_target)\n",
        "print(rf.feature_importances_)\n",
        "\n",
        "# 앞에 1절 결정 트리에서 만든 특성 중요도와 다른 이유는?\n",
        "# 랜덤 포레스트가 틀성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문 !\n",
        "# 그 결과 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻음.\n",
        "# !! 과대적합을 줄이고 일반화 성능을 높이는데 도움이 됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls8wSDI8RENb",
        "outputId": "3328fc2f-5d3c-4864-efda-5baef91fe772"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자체적으로 모델을 평가하는 기능이 있다?\n",
        "# 랜덤 포레스트는 부트스트랩 샘플에 포함되지 않고 남은 샘플(OOB샘플)로 결정 트리를 평가할 수 있다.\n",
        "\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1,random_state=42)\n",
        "rf.fit(train_input,train_target)\n",
        "print(rf.oob_score_)\n",
        "\n",
        "# OOB점수를 사용하면 교차 검증을 대신할 수 있어 결과적으로 훈련 세트에 더 많은 샘플을 사용할 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olHwgpdUSkhx",
        "outputId": "cc955b0b-4685-48f1-dce9-e4d5fcf5a1d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 엑스트라 트리"
      ],
      "metadata": {
        "id": "lkWZHJZPTajR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑스트라 트리는 랜덤 포레스트와 매우 비슷하게 동작\n",
        "# 다른 점은 부트스트랩 샘플을 사용하지 않는다는 점!\n",
        "# 전체 훈련 세트를 사용해서, 노드를 분할할 때 가장 좋은 분할을 찾는 것이 아니라 무작위로 분할\n",
        "# splitter = 'random'\n",
        "# 하나의 결정 트리에서 특성을 무작위로 분할한다면 성능이 낮아지겠지만 많은 트리를 앙상블 하기 때문에\n",
        "# 과대적합을 막고 검증 세트의 점수를 높이는 효과가 있다."
      ],
      "metadata": {
        "id": "IRkhbx7RTbUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et,train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnc4opg7T6bO",
        "outputId": "8b4c40fb-13ff-4806-a171-9f8fc851ef78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 중요도\n",
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAwyWG_cU7vD",
        "outputId": "4314ed4d-ba5c-4320-f367-3d34e27e309f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 그레이디언트 부스팅"
      ],
      "metadata": {
        "id": "lUyc7wbBVgeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식\n",
        "# 경사 하강법을 사용하여 트리를 앙상블에 추가\n",
        "# 학습률 매개변수로 속도를 조절할 수도 있음 ㅇㅅㅇa"
      ],
      "metadata": {
        "id": "6GjgZ_ENViQ5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
        "\n",
        "# 그레이디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 매우 강함!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2doKwZP3V2rA",
        "outputId": "f02e06ea-9872-47d9-9322-51f9ee4a6a2e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결정트리 개수 5배 늘려보기\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(n_estimators=500,learning_rate=0.2,random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
        "\n",
        "# 과대적합을 잘 억제하는 모습을 보임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmS_I86pXOgs",
        "outputId": "09c458fc-2abd-447a-b815-398f2ab58b4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)\n",
        "\n",
        "# 그레이디언트 부스팅이 랜덤 포레스트보다 일부 특성(당도)에 더 집중하는것을 알 수 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FNXGD2mWYnp",
        "outputId": "60090a15-213a-4581-b85c-10ef22b60acc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 히스토그램 기반 그레이디언트 부스팅"
      ],
      "metadata": {
        "id": "pENPwcyTYhdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 특성을 256개의 구간으로 나눈다.\n",
        "# 256개 구간 중에서 하나를 떼어 놓고 누락된 값을 위해서 사용\n",
        "\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb,train_input, train_target, return_train_score=True)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs73ItXgYjNk",
        "outputId": "ca69657c-0527-468b-e96a-5019ec1eed49"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 과대적합을 잘 억제하면서 그레이디언트 부스팅보다 조금 더 좋은 성능을 제공해준다\n",
        "# 특성 중요도 확인해보자! -> permutation_importance()\n",
        "# 이 함수는 특성을 하나씩 랜덤하게 섞어서 모델의 성능이 변화하는지를 관찰하여\n",
        "# 어떤 특성이 중요한지를 계산\n",
        "from sklearn.inspection import permutation_importance\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)\n",
        "\n",
        "# 히스토그램 기반 그레이디언트 부스팅 모델을 훈련하고 훈련 세트에서 특성 중요도 계산\n",
        "# n_repeats 매개변수는 랜덤하게 섞을 횟수를 지정\n",
        "\n",
        "# 반환 객체에는 특성 중요도, 평균, 표준 편차를 담고 있음.\n",
        "\n",
        "# 두 번째 속성을 섞으면 정확도가 0.23만큼 떨어진다.. 그만큼 중요하다!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-k4FmLfZj68",
        "outputId": "a8c9f178-89a4-419d-b9e9-b665a19d8e17"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 세트에서 특성 중요도 계산\n",
        "result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf9HD8-JcE-w",
        "outputId": "40c96be6-28db-48dc-be1d-b6fdeb38bf7f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 세트에서의 성능 확인\n",
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOvIpbNfcJmQ",
        "outputId": "0a8c4615-2f78-4fca-b78e-175ff609cf5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost\n"
      ],
      "metadata": {
        "id": "qr6qxFx3d4ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "# 사이킷런 말고도 히스토그램 기반 그레이디언트 부스팅 알고리즘을 구현한 라이브러리가 많다\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(tree_method = 'hist',random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target, return_train_score=True)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwwhmxyRd6F3",
        "outputId": "7de210cf-7605-47b5-f19a-082f04948d4b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9555033709953124 0.8799326275264677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "5t4re3K1eY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUQXxIKSea-l",
        "outputId": "cd10bc95-70b8-42e3-edec-2c59afdb269e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.935828414851749 0.8801251203079884\n"
          ]
        }
      ]
    }
  ]
}